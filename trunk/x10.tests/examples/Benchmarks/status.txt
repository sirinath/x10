------- KEY ISSUES:

Java back-end is considerably slower (typically 10-20x) than
hand-coded Java on most tests. Two recent changes (generated code for
++, final methods for closures) has made this worse for some tests,
better for others.

Parallel UTS is 30x slower than sequential UTS with Java back
end. (Parallel version does not yet work with C++ back end). Probably
due to excessive memory allocation.

C++ back-end X10-style loop test without GC fails by running out of
memory due to unnecessary allocation of Point.

Sequential UTS is 4.5x slower than hand-coded with C++ back
end. Profiling shows likely due to handling of primitive casts.

Sequential random access is 3.3x slower than hand-coded with C++ back
end. Profiling shows likely due to handling of primitive casts.

Wrapping rail access in a minimal array-like class (with apply and
set) costs 2-3x in peformance with both Java and C++ back end.

C++ back-end is faster than Java back-end for the simple tests (rail,
non-generic pseudo-array), slower for the more complex tests (generic
array, sequential UTS).

Matrix multiply is 450x slower than hand-coded with C++ back-end and
80x slower than hand-coded with Java back-end. Profiling doesn't seem
to show any additional sources of inefficiency besides those already
revealed by the above more focussed tests.

With C++ back-end distributed stream shows a slowdown relative to
sequential. (Two processes, sockets, Cygwin.) A little surprising even
given the issues with the implementation of distribution because this
app does very coarse-grained operations. Needs more investigation.

With C++ back-end distributed random access is substantially slower
than sequential. (Two processes, sockets, Cygwin.) Not surprising
given the current distribution implementation issues and the use of
sockets for this test.


------- PERFORMANCE DATA:

                    cpp-opt        x10-cpp-opt    java-opt       x10-java-opt   

SeqRail2            a: 266  Mop/s  b: 216  Mop/s  c: 267  Mop/s  d: 12.2 Mop/s
SeqPseudoArray2a    e: 267  Mop/s  f: 76.2 Mop/s  g: 265  Mop/s  h: 25.5 Mop/s
SeqPseudoArray2b                   i: 76.0 Mop/s                 j: 25.5 Mop/s
SeqArray2a                         k: 2.15 Mop/s                 l: 8.26 Mop/s
SeqArray2b                                                       m: 12.3 Mop/s

SeqUTSBin1          n: 7.10 Mop/s  o: 1.61 Mop/s  p: 9.03 Mop/s  q: 5.05 Mop/s
ParUTSBin1                                                       r: 176  kop/s

SeqMatMultAdd1a     s: 239  Mop/s  t: 535  kop/s  u: 352  Mop/s  v: 5.18 Mop/s

SeqStream1          w: 116  Mop/s  x: 114  Mop/s  y: 117  Mop/s  z: 3.56 Mop/s
ParStream1                         A: 122  Mop/s                 B: 39.2 Mop/s
DistStream1                        C: 48.8 Mop/s                 D: 37.6 Mop/s

SeqRandomAccess1    E: 54.5 Mop/s  F: 16.8 Mop/s  G: 35.6 Mop/s  H: 7.36 Mop/s
ParRandomAccess1                   I: 29.4 Mop/s                 J: 6.32 Mop/s
DistRandomAccess1                  K: 3.32 kop/s                 L: 120  kop/s

------- COMPARISONS:

C++ back end relative to hand-coded
    rail access                  1.2x slower (a/b)
    non-generic pseudo-array     3.5x slower (e/f)
    generic pseudo-array         3.5x slower (e/i)
    array w/ c-style loop      124.5x slower (e/k)
    sequential UTS               4.4x slower (n/o)
    matrix multiply            447.0x slower (s/t)
    sequential frag. stream      1.0x slower (w/x)
    sequential random access     3.3x slower (E/F)

Java back end relative to hand-coded
    rail access                 21.8x slower (c/d)
    non-generic pseudo-array    10.4x slower (g/h)
    generic pseudo-array        10.4x slower (g/j)
    array w/ c-style loop       32.1x slower (g/l)
    array w/ x10-style loop     21.5x slower (g/m)
    sequential UTS               1.8x slower (p/q)
    matrix multiply             67.9x slower (u/v)
    sequential frag. stream     32.9x slower (y/z)
    sequential random access     4.8x slower (G/H)

C++ back end relative to Java back end
    rail access                 17.7x faster (b/d)
    non-generic pseudo-array     3.0x faster (f/h)
    generic pseudo-array         3.0x faster (i/j)
    array w/ c-style loop        3.8x slower (l/k)
    sequential UTS               3.1x slower (q/o)
    matrix multiply              9.7x slower (v/t)
    sequential frag. stream     32.1x faster (x/z)
    sequential random access     2.3x faster (F/H)

C++ generic vs non-generic       1.0x slower (f/i)

UTS par. speedup (Java)         28.6x slower (q/r)

Stream par. speedup (Java)      11.0x faster (B/z)
Stream par. speedup (C++)        1.1x faster (A/x)

Stream dist. speedup (Java)     10.6x faster (D/z)
Stream dist. speedup (C++)       2.3x slower (x/C)

Rand. access par. speedup (Java)   1.2x slower (H/J)
Rand. access par. speedup (C++)   1.8x faster (I/F)

Rand. access dist. speedup (Java)  61.5x slower (H/L)
Rand. access dist. speedup (C++) 5044.1x slower (F/K)

------- COLUMNS:

cpp-opt       hand coded C++, compiled g++ -O3

x10-cpp-opt   X10 with C++ back end, compiled g++ -O3 with checking off

java-opt      hand coded Java

x10-java-opt  X10 with Java back end, checking off

------- ROWS (TESTS):

The first five tests are grouped together because they do essentially
the same work (from the application perspective) and so should ideally
perform the same.

SeqRail2

    Basic rail performance test. Allocate a rail, assign values to
    each element, read it back. Test is written to simulate treating
    the rail as a 2-d array in order (nested loop with index
    calculation) to facilitate comparisons with array performance
    tests SeqPseudoArray2{a,b} and SeqArray2

SeqPseudoArray2a

    Does the same work as SeqRail2, but wrapped in a class with an
    apply and set method to simulate the "best possible" X10 code for
    a 2-d double (non-generic) array class.

SeqPseudoArray2b

    Like SeqPseudoArray2a, but generic instead of double.

SeqArray2a

    The actual x10.lang.Array code, using a C-style loop.

SeqArray2b

    The actual x10.lang.Array code, using an X10-style loop with
    destructured points.

SeqUTSBin1

    Sequential version of an the Unbalanced Tree Search
    benchmark. Recursively visits nodes of a randomly generated tree.

ParUTSBin1

    Parallel version of an the Unbalanced Tree Search
    benchmark. Recursively visits nodes of a randomly generated tree.

SeqStream1

    Sequential simplified (rail-only) fragmented stream.

ParStream1

    Parallel version of above.

DistStream1

    Distributed version of above.

SeqRandomAccess1

    Sequential simplified (rail-only) fragmented random access.

ParRandomAccess1

    Parallel version of above.

DistRandomAccess1

    Distributed version of above.
