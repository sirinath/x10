------- KEY ISSUES:

Parallel UTS is 50x slower than sequential UTS with Java back
end. (Parallel version does not yet work with C++ back end). Probably
due to excessive memory allocation.

Using generic classes vs non-generic costs 30x in peformance with C++
back end. Profiling shows probably due to 16 extra method calls per
update (=apply/set pair) in generic vs non-generic.

C++ back-end X10-style loop test without GC fails by running out of
memory due to unnecessary allocation of Point.

Rail access is 5x slower than hand-coded with Java back end. Profiling
shows likely due to boxing.

Sequential UTS is 4.5x slower than hand-coded with C++ back end.

Rail access is 2x slower than hand-coded with C++ back-end. 

Wrapping rail access in a minimal array-like class (with apply and
set) costs 2x in peformance with both Java and C++ back end.

C++ back-end is faster than Java back-end for the simple tests (rail,
non-generic pseudo-array), slower for the more complex tests (generic
array, sequential UTS).

Matrix multiply is 450x slower than hand-coded with C++ back-end and
80x slower than hand-coded with Java back-end. Profiling doesn't seem
to show any additional sources of inefficiency besides those already
revealed by the above more focussed tests.

With C++ back-end distributed stream shows a slowdown relative to
sequential. (Two processes, sockets, Cygwin.) A little surprising even
given the issues with the implementation of distribution because this
app does very coarse-grained operations. Needs more investigation.


------- PERFORMANCE DATA:

                    cpp-opt        x10-cpp-opt    java-opt       x10-java-opt   

SeqRail2            a: 248  Mop/s  b: 115  Mop/s  c: 250  Mop/s  d: 46.8 Mop/s  2008-12-15 
SeqPseudoArray2a    e: 250  Mop/s  f: 61.3 Mop/s  g: 248  Mop/s  h: 25.5 Mop/s  2008-12-15 
SeqPseudoArray2b                   i: 2.15 Mop/s                 j: 24.7 Mop/s  2008-12-15 
SeqArray2a                         k: 2.12 Mop/s                 l: 22.3 Mop/s  2008-12-15 
SeqArray2b                                                       m: 8.69 Mop/s  2008-12-15 

SeqUTSBin1          n: 7.16 Mop/s  o: 1.61 Mop/s  p: 9.72 Mop/s  q: 8.52 Mop/s  2008-12-15 
ParUTSBin1                                                       r: 172  kop/s  2008-12-15 

SeqMatMultAdd1a     s: 235  Mop/s  t: 525  kop/s  u: 333  Mop/s  v: 4.19 Mop/s  2008-12-15 

SeqStream1          w: 111  Mop/s  x: 44.3 Mop/s  y: 111  Mop/s  z: 16.0 Mop/s  2008-12-15 
ParStream1                         {: 101  Mop/s                 |: 37.8 Mop/s  2008-12-15 
DistStream1                        }: 37.2 Mop/s                 ~: 38.1 Mop/s  2008-12-15 


------- COMPARISONS:

C++ back end relative to hand-coded
    rail access                  2.2x slower (a/b)
    non-generic pseudo-array     4.1x slower (e/f)
    generic pseudo-array       116.3x slower (e/i)
    array w/ c-style loop      117.9x slower (e/k)
    sequential UTS               4.4x slower (n/o)
    matrix multiply            448.4x slower (s/t)
    sequential frag. stream      2.5x slower (w/x)

Java back end relative to hand-coded
    rail access                  5.3x slower (c/d)
    non-generic pseudo-array     9.7x slower (g/h)
    generic pseudo-array        10.0x slower (g/j)
    array w/ c-style loop       11.1x slower (g/l)
    array w/ x10-style loop     28.6x slower (g/m)
    sequential UTS               1.1x slower (p/q)
    matrix multiply             79.4x slower (u/v)
    sequential frag. stream      6.9x slower (y/z)

C++ back end relative to Java back end
    rail access                  2.5x faster (b/d)
    non-generic pseudo-array     2.4x faster (f/h)
    generic pseudo-array        11.5x slower (j/i)
    array w/ c-style loop       10.5x slower (l/k)
    sequential UTS               5.3x slower (q/o)
    matrix multiply              8.0x slower (v/t)
    sequential frag. stream      2.8x faster (x/z)

C++ generic vs non-generic      28.6x slower (f/i)

UTS par. speedup (Java)         49.4x slower (q/r)

Stream par. speedup (Java)       2.4x faster (|/z)
Stream par. speedup (C++)        2.3x faster ({/x)

Stream dist. speedup (Java)      2.4x faster (~/z)
Stream dist. speedup (C++)       1.2x slower (x/})


------- COLUMNS:

cpp-opt       hand coded C++, compiled g++ -O3

x10-cpp-opt   X10 with C++ back end, compiled g++ -O3 with checking off

java-opt      hand coded Java

x10-java-opt  X10 with Java back end, checking off

------- ROWS (TESTS):

The first four tests are grouped together because they do essentially
the same work (from the application perspective) and so should ideally
perform the same.

SeqRail2

    Basic rail performance test. Allocate a rail, assign values to
    each element, read it back. Test is written to simulate treating
    the rail as a 2-d array in order (nested loop with index
    calculation) to facilitate comparisons with array performance
    tests SeqPseudoArray2{a,b} and SeqArray2

SeqPseudoArray2a

    Does the same work as SeqRail2, but wrapped in a class with an
    apply and set method to simulate the "best possible" X10 code for
    a 2-d double (non-generic) array class.

SeqPseudoArray2b

    Like SeqPseudoArray2a, but generic instead of double.

SeqArray2a

    The actual x10.lang.Array code, using a C-style loop.

SeqArray2b

    The actual x10.lang.Array code, using an X10-style loop with
    destructured points.

SeqUTSBin1

    Sequential version of an the Unbalanced Tree Search
    benchmark. Recursively visits nodes of a randomly generated tree.

ParUTSBin1

    Parallel version of an the Unbalanced Tree Search
    benchmark. Recursively visits nodes of a randomly generated tree.

SeqStream1

    Sequential simplified (rail-only) fragmented stream.
