I am slowly working my way through the paper (Wen + Collella), and Phil's slides, with the aim of understanding all the details, and have several questions.

(1) Can you ask Phil if the code he describes in his SciDAC 07 talk (with the scaling to thousands of processors) is the code available from the Chombo download?

(2) I have created x10.apps/AMR as a working directory for the new AMR work in X10. I believe that Doug Lovell's code lives in a top-level AMR directory on the Purdue CVS. Did you also create a separate AMR directory?

(3)  Phil's slides

Slide 15: Morton ordering allocation of patches to processors ... is this done "offline" (i.e. is the time to determine allocation not measured?)
Exchanging ghost-cell data less frequently in point relaxation ... what does this mean?

Slide 16: Why is it necessary for every processor to have a copy of the meta-data?

Slide 19: What does rebalancing mean? Is there some on-the-fly load balancing?

I am still quite confused about regridding. Shouldnt there be some step where based on the data values a determination is made about which part of the mesh to further refine. This will then lead to computation to determine the partitioning of patches to processors. Is this all done in parallel? Or is this done statically, between the timed runs of the algorithm? (In the latter case it would seem to me that AMR has not been completely parallelized...)

I know I keep asking this question! Perhaps this is what "Parallel grid generation" on P23 is all about.

P23 talks about load-balancing based on run-time measurements (already done in LMC). So some form of dynamic load-balancing is implemented!

P23: What are "line solves".

P24: has the parallel load balancing algorithm been developed already? 

(4) Questions on your paper: The basic problem I have is that the presentation is geared towards a computational scientist -- so a lot of applied mathematics is assumed. If the paper was written a bit more carefully it could be accessible to a much wider audience, e.g. computer scientists. 

Here are the things I struggled with:

(a) As a computer scientist I am extremely concerned about representational and inferencing and computational issues. So on P2, when you say L phi = f in Omega (2.1), I want to know ... how are L, phi, f and Omega represented? 

Is f implemented as a fixed (unchanging) array at each refinement level?

L is the Laplacian. Good. So then it is represented in code??

I take it phi is the solution we are after. We are given the value of phi on the boundary of Omega --- is that what "do Omega" is in (2.2)?

(b)  Bottom of Page 2, col 2. Isnt it the case that each multidimensional array has to be represented in the Fortran style, so that Fortran code can be run to perform stencil operations?

(c) Page 3 claim -- "basic AMR operations are implemented in 1200
lines of Titanium code, whereas the corresponding part in Chombo has
around 6500 lines of code." I dont understand why. In fact I am quite
surprised. A good OO design in Chombo should yield about the same line
count as the Titanium code.

(d) Page 3 Dont understand: "In the multigrid algorithm described
here, a simplified version of L^l denoted by L^l_nf is also used,
where it is assumed there is no finer levels above l." Did you mean
... no finer levels above nf?

How is L^l_nf represented? I see it takes two arguments, whereas L^l
takes only one argument.

(e) Is this multigrid method an implicit method? Can I match up
successive values of phi obtained by applying a V cycle to progress in
time? I think not. I think this is an implicit method and successive V
cycles are helping get closer and closer to the root. That is why one
terminates when the norm is small. PLEASE VERIFY.

(f) The code in Figure 2 is highly confusing. To make computational
sense, I need a lot more details.

1  procedure AMRSolve():
2    R^comp = f^comp - L^comp(phi^comp)
3 while (||R^comp|| > e ||f^comp||)
4     AMRVCycle(l_max)
5     R^comp = f^comp - L^comp(phi^comp)
6 end while

OK. Here is what I dont know

   -- What is the datatype associated with R^comp, f^comp, L^comp and
      phi^comp?

      My guess is that R represents a residual and is implemented as
      an array of doubles. But does this array have one element per
      processor, or one element per patch, i dont know.

   -- Where are these variables declared, i.e. are these global
      variables?

   -- How are they initialized? On entry to ARMSolve, f, L and phi are
      read. So they already have values! Where did these values come
      from? e.g. is the phi value a "guess"? if so, how does one make
      the initial guess?

   -- My guess is that AMRVCyle side-effects R and phi -- that is the
      reason for invoking it. And e, phi and delta are local variables
      in AMRVCycle whose value is not carried over from one invocation
      of AMRVCycle to another.

      Is delta e related to e in any way, or is it a completely
      different variable?

   -- What is the communication and computation structure of line 2
      (and line 5) above? i.e. is this all done in (data-)parallel
      using an owners-compute rule, with a barrier at the end?

   -- Similarly is AMRVCycle invoked by one processor? All processors?
      (I suspect all processors.) i.e. is the pseudo-code an SPMD code
      or a forkjoin code?

   -- I want to see an abstraction of the actual code, with the step
      for filling in the ghost cells. This way I can see where there
      is communication and where there is computation.

   -- Where is Interpolate defined? My suspicion is that its
      definition is very simple. One simply fits a linear curve
      between two given end points to compute the required value at an
      intermediate point, right?

   -- I have no idea what Omega^f_BLACK and Omega^f_RED are!! Prolly a
      coloring of the patches are RED and BLACK so that we avoid
      read/write conflicts.


The structure of a "V" cycle arises because there is a recursive call
to AMRVCycle in the body of AMRVCycle. The code before this call is
executed on the way down in the V-cycle and the code after it is
executed on the way back up. The "nested V" arises because mgRelax has
a similar recursive call to mgRelax.

BTW I have started a glossary.txt -- please feel free to update it. 