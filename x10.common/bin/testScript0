#!/bin/bash
# Author: kemal, 1/2005
# Simple script to run test cases
# until a better solution is found.

chkArgs() {
# check number of arguments
# e.g. chkArgs 3 a b c
# used for verifying a fixed number of arguments

local num="$1"
shift
if [[ $# -ne $num ]]; then 
	echo "Argument count error, expecting $num, found $#"
	exit 1
fi
}

usage() {
# print usage message and exit with nonzero return code
chkArgs 0 "$@"

echo "

Usage:

testScript [-cleanOnly] [-f] [-t timeLimit] [-shiftLog] [ -m userEmail]
[-testList fileName] [-test test1 test2 ...]

Runs the *.x10 test cases in the current directory and
subdirectories, and places the test results in a file called
\"log\". The -m userEmail causes the log file to emailed to the
given user.

The -t timeLimit parameter specifies how many seconds to wait
(in terms of wall clock time) in each compilation and run step,
before killing the process. If the time limit is exceeded in any
step, the testcase is assumed to fail.  By default timeLimit is
60 seconds.

The shiftLog parameter causes the current results  to be saved,
so running the testScript later in the same directory will cause
a diff with the previous results to be mailed out as well, when
the -m userEmail option flag is present.

An X10 test case file *.x10 contains a single public class, which
has a \"public boolean run()\" instance method, and a \"public
static void main(String args[])\"  method.  The run method must
contain the actual test and must return true if the test passed.
run() must throw an exception or return false to indicate failure.
The main method must create the class with an empty constructor,
invoke its run method, print  the result (Test succeeded or Test
failed), and exit with a zero return code if the test succeeded,
and a nonzero return code otherwise.  This makes the test case
compatible with both the x10c/x10 command (which invokes the main
method) and junit (which invokes the run method on a new instance).

Run this script in the top-level directory where the *.x10
testcases are. The current directory must have a magic file
\".ThisIsAnX10TestDirectory\" present in the directory, to
reduce the chances of accidentally deleting *.{java,class} files
elsewehere.  To run testScript in the current directory, even if
this file is not present, you can specify the -f option (force).

The file hierarchy starting at the top test directory is scanned
in a pre-order (depth-first) enumeration.  Top level directories
that do not contain *.x10 files are considered organizational
directories, not containing packages or test cases. As soon
as a directory containing any *.x10 files, is encountered in
the pre-order traversal, all the .x10 files containing \"public
static void main\" methods in this directory and subdirecties are
executed (using the preorder enumeration) as test cases, with the
x10 classpath set to this directory.  The subdirectories may have a
package/subpackage organization as in java.  Files and directories
in a given directory are processed in alphabetical name order.

It is possible to specify that a test case must fail. You
can specify the kind of expected failure in the file
name, fn_MustFailCompile.x10, fn_MustFailRun.x10, or
fn_MustFailTimeout.x10. If there is no _MustFail* suffix, the
test case must succeed.  Each test case is expected to meet
the specified expectation (Succeed, FailCompile, FailRun, and
FailTimeout). The \"log\" script reports the test cases that did
not meet expectations.

To avoid running an *.x10 file as a test case, do not put a
\"public static void main\" method in it.  This is the way to
define auxiliary classes that are not themselves test cases.

It is also possible to declare a test case as an implementation
limitation. Just use \"//LIMITATION:\" as the first line of
the main .x10 file of the test case. All test cases not meeting
expectations will still be reported, but the string \"LIMITATION:\"
will show up in the log file before the test cases declared as
a limitation. This is helpful for focusing on the problems that
can be fixed in the nearer term.

Additional option flags:

The -cleanOnly option just cleans up left-over intermediate files
from a previous run and exits immediately.

The -testList option indicates a file containing a list of shell
file patterns denoting the tests to run. The test list file can
also contain comment lines beginning with a \"#\" character,
and blank lines, for clarity. Alternatively, the -test option
indicates the file pattern(s) for the tests to run. With these
options, only the specified tests are run. For example:

testScript -test \"Constructs/*/FutureTest*.x10\"

will only run the tests matching the given pattern.

The -h, -help or --help option will print this message. Use: 

testScript -h | less

"

exit 1

}

checkUsage() {
# Process the arguments.
# Also perform simple checks before running script.

  timeLimit=60
  mailDest=""
  shiftLog=""
  cleanOnly=""
  force=""
  pat=""
  x10lib="./x10lib"
  while [[ $# -gt 0 ]]; do
    if [[ "$1" = "-t"  && $# -ge 2 ]]; then
      timeLimit="$2"
      shift 2
    elif [[ "$1" = "-testList"  && $# -ge 2 && -r "$2" ]]; then
      #remove comments and blank lines
      pat=$(cat "$2"| egrep -v '^([[:space:]]*#.*|[[:space:]]*)$') 
      shift 2
    elif [[ "$1" = "-test"  && $# -ge 2 ]]; then
      shift
      pat="$*"
      break
    elif [[ "$1" = "-help" || "$1" = "-h" || "$1" = "--help" ]]; then
      usage
    elif [[ "$1" = "-shiftLog" ]]; then
      shiftLog="yes"
      shift
    elif [[ "$1" = "-cleanOnly" ]]; then
      cleanOnly="yes"
      shift
    elif [[ "$1" = "-f" ]]; then
      force="yes"
      shift
    elif [[ "$1" = "-m" && $# -ge 2 ]]; then
      mailDest="$2"
      shift 2
    elif [[ "$1" = -* ]]; then
      echo "unrecognized flag $1, or missing argument"
      usage
    else
      echo "extraneous argument $1"
      usage
    fi
  done
  if [[ ! -e .ThisIsAnX10TestDirectory && -z "$force" ]] ; then
    echo "You must be in an X10 test directory to run this script"
    echo "The file .ThisIsAnX10TestDirectory must be present"
    usage
  fi
}

cleanClasses() {
# clean the .java .class and .pem leftover files
chkArgs 0 "$@"

  find . \( -name '*.java' -o -name '*.class' -o -name '*.pem' -o -name '*_x10stub.c' -o -name 'javacore*' -o -name 'heapdump*' -o -name '*.stackdump' -o -name 'log*' -o -name 'TMP_*' \) -exec rm {} \; 
}

clean() {
# remove leftover files from previous runs

  chkArgs 0 "$@"
  cleanClasses
  #in case no one else has done this make .so files executable
  find . \( -name '*.so' -o -name '*.dll' \) -exec chmod ugo+rx  {} \;
}

testForMain() {
# test that tail is of the form *.x10 and
# there is a main method in file f

    chkArgs 2 "$@"
    local f="$1"
    local tail="$2"
    if [[ "$tail" != *.x10 ]] ; then return 1; fi
    egrep '(public[[:space:]]+static|static[[:space:]]+public)[[:space:]]+void[[:space:]]+main' "$f" >/dev/null
    return $?
}

removeDotSlash() {
# convert ./a/b/./c to a/b/c 

  chkArgs 1 "$@"
  local str=$1
  #str=${str//\.\//}
  str=`echo "$str" | sed -e 's/\.\///g'`

  RESULT=$str
}

testInList() {
# true(0) iff $f matches one of the patterns in $pat
# or $pat is empty

chkArgs 1 "$@"
local f="$1"
removeDotSlash "$f"
f="$RESULT"
if [[ -z "$pat" ]]; then return 0; fi
for i in $pat ; do 
  if [[ "$f" = $i ]] ; then
	return 0
  fi
done
return 1
}

testForEligibility() {
# Checks if an .x10 file is really a test
# True(0) if  file $f contains "public static void main" and 
# the file name matches one of the patterns in -test or -testList
    chkArgs 2 "$@"
    local f="$1"
    local tail="$2"
    testForMain "$f" "$tail" && testInList "$f"
}



genTest() {
# Top level call will be: genTest "." "."

# executed at the top level test directory

# The file hierarchy starting at the top test directory is scanned
# in a pre-order (depth-first) enumeration.  Top level directories
# that do not contain *.x10 files are considered organizational
# directories, not containing packages or test cases. As soon
# as a directory containing any *.x10 files, is encountered in
# the pre-order traversal, all the .x10 files containing "public
# static void main" methods in this directory and subdirecties are
# executed (using the preorder enumeration), as test cases.
# The x10 classpath is set to this directory, while
# recursively processing the test cases contained in the directory.
# Files and directories in a given directory are processed in 
# alphabetical name order.

  chkArgs 2 "$@"
  local srcDir="$1" #current directory relative to X10 classpath
  local testDir="$2" #X10 classpath relative to top directory
  local tail=""
  # $testDir/$srcDir/ is the current directory to process
  ls $testDir/$srcDir/*.x10 >/dev/null 2>&1
  local X10Files="$?" #0 if *.x10 files exist in current directory
  for f in $testDir/$srcDir/*; do
    tail=${f##*/} # if f is a/b/c tail will be c
    if [[ -d "$f" && "$tail" != CVS && "$srcDir" = "." && $X10Files -ne 0 ]]; then
      # still in the top level organizational directories
      # not containing x10 test cases
      genTest "." "$testDir/$tail"  #this is an organizational  subdir
    elif [[ -d "$f" && "$tail" != CVS ]]; then
      # either $srcDir (x10 classpath) is already found above.
      # or $srcDir is the first encountered directory with *.x10 files in it
      genTest "$srcDir/$tail" "$testDir" #recursively generate tests for package subdir
    elif testForEligibility "$f" "$tail"; then
      # an actual .x10 file containing a main method
      # and also matches one of the specified filename patterns 
      doTest $srcDir $testDir ${tail%.x10} # run an actual x10 test case
    fi
  done
}

correctExitCode() {
# Does additional checks on the output of a command and
# makes the exit code nonzero if necessary.
# $rc is the original exit code.
# If the original exit code $rc is already nonzero, or if 
# $mustFindPat is null, return the original exit code $rc.
# Otherwise, check that the result of the command
# contains $mustFindPat and does not contain $mustNotFindPat.
# If not, return a nonzero exit code, otherwise return
# the original exit code (0).

chkArgs 4 "$@"
local mustFindPat="$1"
local mustNotFindPat="$2"
local rc="$3"
local tmpFile="$4"

# if rc is already nonzero or no pattern match is required
# return the existing exit code
if [[ -z "$mustFindPat" || "$rc" -ne 0 ]]; then return "$rc"; fi 

egrep "$mustFindPat" $tmpFile >/dev/null 
local mustFindRc=$?

egrep "$mustNotFindPat" $tmpFile >/dev/null 
local mustNotFindRc=$?

if [[ "$mustFindRc" -eq 0 && "$mustNotFindRc" -ne 0 ]]; then
    return $rc # matched patterns in output, OK
fi

return 42 # zero exit code was misleading, force nonzero exit code

}

makeTempFile() {
#create a temporary file name

  chkArgs 1 "$@"
  local fn="$1"
  let "tmpFileNum = (( $tmpFileNum + 1 ))"
  RESULT="TMP_${fn}_${tmpFileNum}"
}

runWithTimeLimit() {
# Run the command $cmd with a wall clock time limit.
# Return the (possibly corrected) exit code of $cmd. 
# A main process group running $cmd, 
# and a "deadman timer" process group that waits maxsec seconds and
# then kills the main process group, are created.
# If the main process group ends before the timer process
# group, the timer process group is killed.
# The output of $cmd is saved in the logDetail.$tdir.$className 
# file.


  chkArgs 5 "$@"
  local tdir="$1" # the current directory
  local className="$2" # the class name
  local cmd="$3"       # the command
  local mustFindPat="$4"       # required pattern in output
  local mustNotFindPat="$5"    # output should not have this pattern
  local maxsec="$timeLimit"
  makeTempFile "XXX"
  local tmpFile="$RESULT"
  echo "" > $tmpFile
  # create a new process group so that the main job
  # and all of the its descendant processes can be terminated 
  # as a whole
  newpgrp "$cmd" >> $tmpFile 2>&1 &    #main job
  local pidMain=$!   #remember pid of main job
  newpgrp "sleep $maxsec; /usr/bin/kill -9 -$pidMain" &> /dev/null & #timer job
  local pidTimer=$!  #remember pid of timer job 
  wait $pidMain      # wait until main job finishes, 
                     # either normally or through the timer
  local rcMain=$?    # exit code of main job
  local temp
  if [[ $rcMain -ge 128 ]]; then
    let  "temp = $rcMain - 128" 
    echo "++++++ Got killed by signal $temp"      >> logDetail.$tdir.$className 
    echo "++++++ Time limit was $maxsec seconds"  >> logDetail.$tdir.$className
  fi
  /usr/bin/kill -9 -$pidTimer &> /dev/null #kill the timer job 
  correctExitCode "$mustFindPat" "$mustNotFindPat" "$rcMain" "$tmpFile"
  local rcMain2=$?
  cat $tmpFile >> logDetail.$tdir.$className
  rm -f $tmpFile
  return  $rcMain2    #return (possibly corrected) exit code of main job

}


msgBoth() {
# write a message to the indicated log file and screen

  chkArgs 2 "$@"
  local str="$2"
  local file="$1"

  echo "$str" >> $file
  echo "$str" 
}

msg() {
# write a message to the indicated log file 

  chkArgs 2 "$@"
  local str="$2"
  local file="$1"

  echo "$str" >> $file
}

reverseFile() {
# reverse the file $fn line by line (last line should occur first).
# Written in a portable way (no tac command).

chkArgs 1 "$@"
local fn="$1"
makeTempFile "myTemp"
local myTemp="$RESULT"
cat -n "$fn" | sort -nr | cut -f2- > $myTemp
mv "$myTemp" "$fn"
}

findSinceWhenMsgKeptOccurring() {
# Find the earliest date, since when the same message "$str" kept occurring
# continuously in the test logs.
# If this message did not occur in the last run, or if no test
# logs can be found, return the starting date of this script.

# Slow algorithm,
# but fine for nightly test runs

  chkArgs 1 "$@"
  local str="$1"
  makeTempFile "allTestLogDates"
  local allTestLogDates="$RESULT"
  makeTempFile "buggyTestLogDates"
  local buggyTestLogDates="$RESULT"

  if [[ -d "$testLogs" ]]; then
    #ensure that there is an imaginary first test log
    #where this message did not appear
    echo "2000.01.01_00.00.00" > $allTestLogDates
  
    egrep "$str" $testLogs/logSummary.* |  sed -e 's/^.*logSummary\.//;s/:.*$//' > $buggyTestLogDates
    ls $testLogs/logSummary.* |  sed -e 's/^.*logSummary\.//' >> $allTestLogDates
    reverseFile "$allTestLogDates"
    reverseFile "$buggyTestLogDates"
    
    local n=`diff $allTestLogDates $buggyTestLogDates | sed -n -e 's/^\([0-9]\+\).*$/\1/p' | head -1`
    if [[ -n "$n" && "$n" -gt 1 ]]; then
       let "n = (( $n - 1 ))"
       RESULT=`sed -n -e "${n},${n}p" $allTestLogDates`
    else
       RESULT="$startDate"
    fi
  else
    RESULT="$startDate"
  fi

  rm -f $allTestLogDates
  rm -f $buggyTestLogDates
  return
}

writeLogLine() {
# write str to the logSummary0 file,
# followed by the earliest date since when str appeared 
# continuously in the logs

  chkArgs 1 "$@"
  local str="$1"
  findSinceWhenMsgKeptOccurring "$str"
  local firstDate="$RESULT"
  echo "$str"
  msg logSummary0 "$str	$firstDate"	
}
  

determineExpectedResult() {
# determine the expected result of the test from the name

  chkArgs 1 "$@"
  local className="$1"
  if [[ "$className" = *MustFailCompile* ]]; then
	RESULT="FailCompile"
  elif [[ "$className" = *MustFailRun* ]]; then
	RESULT="FailRun"
  elif [[ "$className" = *MustFailTimeout* ]]; then
	RESULT="FailTimeout"
  elif [[ "$className" = *MustFail* ]]; then
	RESULT="Fail"
  else
	RESULT="Success"
  fi
  return
}

compareExpectedToActualResult() {
#returns true(0) iff expected result is equal to the actual
#result, or the expected result is Fail and the actual
#result is one of FailRun or FailCompile or FailTimeout

  chkArgs 2 "$@"
  local expectedResult="$1"
  local actualResult="$2"
  if [[ "$expectedResult" = "$actualResult" ||
        "$expectedResult" = "Fail" &&
	"$actualResult" = Fail* ]]; then
	return 0
  else
	return 1
  fi
} 

checkLimitation() {
# check if this test case is marked as a limitation of the
# current implementation

  chkArgs 1 "$@"
  local x10FileName="$1"
  makeTempFile "tmpFile"
  local tmpFile="$RESULT"
  local limitation=""
  egrep "^\/\/LIMITATION\:" "$x10FileName" > $tmpFile
  if [[ $? -eq 0 ]]; then
    limitation="LIMITATION: "
  fi  
  rm -f "$tmpFile"
  RESULT="$limitation"
}
  
recordTestResult() {
# check if actual test result matched expected result
# and print in logSummary

  chkArgs 4 "$@"
  local actualResult="$1"
  local tdir="$2"
  local className="$3"
  local x10FileName="$4"
  determineExpectedResult "$className"
  local expectedResult="$RESULT"
  if compareExpectedToActualResult "$expectedResult" "$actualResult"; then
    writeLogLine "$tdir $className met expectation: $actualResult."
  else
    checkLimitation "$x10FileName"
    local limitation="$RESULT"
    if [[ -n "$limitation" ]]; then
      let "nLimitation = (( $nLimitation + 1 ))"
    fi
    writeLogLine "$limitation$tdir $className did not meet expectation: expected=$expectedResult actual=$actualResult."
    let "nFail = (( $nFail + 1 ))" 
  fi
}
    

changeSlashToDot() {
# convert a/b/c to a.b.c , but ./foo becomes foo

  chkArgs 1 "$@"
  local str=$1
  str=${str#\.\/}
  #str=${str//\//\.}
  str=`echo "$str" | sed -e 's/\//\./g'`
  RESULT=$str
}


doTest() {
# run the x10 test case $tstDir/$srcDir/test.x10 

  chkArgs 3 "$@"
  local srcDir="$1"
  local testDir="$2"
  local test="$3"
  local x10FileName="$testDir/$srcDir/$test.x10" #./Misc/./a/b/c.x10
  changeSlashToDot "$srcDir/$test"
  local className="$RESULT"             #a.b.c
  changeSlashToDot "$testDir"
  local tdir="$RESULT"

  echo -e "\n****** $tdir $className ******\n" > logDetail.$tdir.$className

  let "nTotal = (( $nTotal + 1 ))"

  runWithTimeLimit "$tdir" "$className" "x10c -t -v -sourcepath $x10lib -sourcepath $testDir -d $testDir $x10FileName" "" ""

  if [[ $? != 0 ]]; then
    echo -e "\n****** $tdir $className failed: compile" >> logDetail.$tdir.$className
    recordTestResult "FailCompile" "$tdir" "$className" "$x10FileName"
    return
  else
    echo "++++++ Compilation succeeded." >> logDetail.$tdir.$className
  fi


  # the output must contain 'Test succeeded'
  # the output must not contain a java stack traceback
  runWithTimeLimit "$tdir" "$className" "x10 -t -v -classpath $testDir $className" "Test succeeded" "AssertionError|	at .+\(.+\)"
  local runRc=$?

  if [[ $runRc -ge 128 ]]; then
    echo -e "\n****** $tdir $className failed: timeout" >> logDetail.$tdir.$className
    recordTestResult "FailTimeout" "$tdir" "$className" "$x10FileName"
  elif [[ $runRc -ne 0 ]]; then
    echo -e "\n****** $tdir $className failed: run" >> logDetail.$tdir.$className
    recordTestResult "FailRun" "$tdir" "$className" "$x10FileName"
  else 
    echo -e "\n****** $tdir $className succeeded." >> logDetail.$tdir.$className
    recordTestResult "Success" "$tdir" "$className" "$x10FileName"
  fi

  return
}

initAll() {
# initialize variables, intermediate files

  chkArgs 0 "$@"
  let "nTotal = 0" #total tests
  let "nFail  = 0" #tests that did not meet expectations
  let "nLimitation = 0" #tests that failed but were limitations
  rm -f logSummary0              # summary for each each test
  touch logSummary0              # ensure file exists  
  rm -f logDetail.*             # details for each test
  rm -f logBegin                # Header file
  startDate=`date '+%Y.%m.%d_%H.%M.%S'`
  testLogs="../../x10web/html/testLogs"
  if [[ -d "$testLogs" ]]; then
    (cd $testLogs; cvs -q up -dPA)
  else
    echo "Warning: directory $testLogs was not found"
  fi
}

generateFinalLog() {
#generate the final log file
  chkArgs 3 "$@"
  local nTotal="$1"
  local nFail="$2"
  local nLimitation="$3"
  local nPass
  makeTempFile "logTemp2"
  local logTemp2="$RESULT"
  makeTempFile "logDetail2"
  local logDetail2="$RESULT" 
  cat logBegin > log
  rm -f logBegin
  let "nPass = (( $nTotal - $nFail ))"
  makeReadableDate "$startDate"
  local date2="$RESULT"
  echo "X10 tests started on $date2" >> log
  echo "$nPass tests out of $nTotal met expectations. $nFail (including $nLimitation implementation limitations) did not meet expectations." >> log
  echo -e "\nThe dates after each error message below show the earliest test run since which the same error message kept occurring continuously.\n" >> log
  if [[ $nTotal -eq 0 ]] ; then
	msgBoth log "Warning: No applicable test was found"
  fi
  makeTempFile "logTemp0"
  local logTemp0="$RESULT"
  sort -t "	" -r +1 -2 logSummary0 |  \
   sed -e 's/\.	\([0-9]\+\)\.\([0-9]\+\)\.\([0-9]\+\)_\([0-9]\+\)\.\([0-9]\+\)\.\([0-9]\+\)/ (\1-\2-\3 \4:\5:\6)./' > $logTemp0
  cut -f1 logSummary0 > logSummary
  rm -f logSummary0
  # report only the failing tests
  grep " did not meet" $logTemp0 > $logTemp2
  echo "" > $logDetail2
  makeTempFile "logTemp3"
  local logTemp3="$RESULT"
  cat $logTemp2 | sed '-e s/^LIMITATION: //' > $logTemp3
  for f in `awk '{print $1 "." $2;}' $logTemp3` ; do 
    cat logDetail.$f >> $logDetail2
  done
  cat $logTemp2 $logDetail2 >> log
  rm -f $logTemp0 $logTemp2 $logDetail2 $logTemp3 
  
  #rm -f logDetail.*
}

makeReadableDate() {
# change yyyy.mm.dd_hh.mm.ss to mm/dd/yyyy hh:mm:ss

  chkArgs 1 "$@"
  local arg="$1"
  local date=${arg%_*}
  local time=${arg##*_}
  local yyyy=${date%%.*}
  local mmdd=${date#*.}
  date="$yyyy.$mmdd"
  #date=${date//./\-}
  date=`echo "$date" | sed -e 's/\./\-/g' `
  #time=${time//./\:}
  time=`echo "$time" | sed -e 's/\./\:/g' `
  RESULT="$date $time"
}


mailDiffFromLastRun() {
# mail differences from last run

  chkArgs 1 "$@"
  local mailDest="$1"
  makeTempFile "logDiff"
  local logDiff="$RESULT"

  local old_logSummary=`ls $testLogs/logSummary.* | tail -1` 
  if [[ -n "$old_logSummary" ]]; then
    local oldStartDate=${old_logSummary#*logSummary.}
    diff -l -w "$old_logSummary" logSummary  > $logDiff
    if [[ $? -eq 0 ]] ; then
      echo "There were no differences." >> $logDiff
    fi
    makeReadableDate "$oldStartDate"
    local date1="$RESULT"
    makeReadableDate "$startDate"
    local date2="$RESULT"
    echo -e "\n\n+++ CVS changes between $date1 ET and $date2 ET (times below are in UTC):" >> $logDiff
    (cd ../..; cvs -q log -d "${date1}<${date2}" -S -b -N `cat x10.common/projectList.txt`|sed -n -e "/^RCS file:/p;/^date:/p;/^=/p"|awk '{print}; END {if(NR==0) print "No changes."}' ) >> $logDiff
    mail -s "X10: differences between test runs started on $date1 vs. $date2" "$mailDest" < $logDiff
    rm -f $logDiff
  fi
}

mailIt() {
# mail test results if there is a destination address
  chkArgs 4 "$@"
  local mailDest="$1"
  local nTotal="$2"
  local nFail="$3"
  local nLimitation="$4"
  local nPass
  let "nPass = (( $nTotal - $nFail ))"
  if [[ -n "$mailDest" ]]; then
    makeReadableDate "$startDate"
    local date2="$RESULT"
    cat log | mail -s "X10 (started $date2): $nPass tests out of $nTotal met expectations. $nFail (including $nLimitation implementation limitations) did not meet expectations." "$mailDest"
    mailDiffFromLastRun "$mailDest" 
  fi
}

generateAndMailFinalLog() {
# generate the final log file and email it to recipient

  chkArgs 0 "$@"
  generateFinalLog "$nTotal" "$nFail" "$nLimitation"
  mailIt "$mailDest" "$nTotal" "$nFail" "$nLimitation" 
}

saveLog() {
# save the log 

  chkArgs 0 "$@"
  if [[ -n "$shiftLog" && -d "$testLogs" ]]; then
    mv logSummary "$testLogs/logSummary.$startDate"
    mv log "$testLogs/log.$startDate"
    local lastDir=`pwd`
    cd $testLogs
      cvs add log*.$startDate  
      makeReadableDate "$startDate"
      local date2="$RESULT"
      cvs commit -m "Test run started on $date2" log*.$startDate
    cd $lastDir
  elif [[ -n "$shiftLog" ]]; then
    msgBoth log "Warning: directory $testLogs was not found" 
  fi
}

finalCleanUp() {
# remove intermediate files

  chkArgs 0 "$@"
# cleanClasses
  saveLog
}

printInfo() {
# print information about system

  msgBoth logBegin "Starting: $0 $*"
  msgBoth logBegin "Machine name: `hostname`"
  msgBoth logBegin "Operating system: `uname`"
  msgBoth logBegin "System load: `w | head -1`"
  msgBoth logBegin ""
}



main() {
# main program

  checkUsage "$@" # check arguments and current directory
  clean         # clean any leftover files
  if [[ -n "$cleanOnly" ]]; then exit 0; fi
  initAll
  printInfo "$@"
  genTest "." "." #run all tests in current directory and subdirectories
  generateAndMailFinalLog
  finalCleanUp
  exit 0
}

main "$@"
exit 0
