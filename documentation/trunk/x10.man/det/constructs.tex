\subsection{Accumulators}
%% Compare with OpenMP reductoin clause.
%% DOMP has arbitrarty reduction types.

Each async (dynamically) has a set of registered \code{@Sync} accumulators
  and \code{@Async} accumulators.
  \begin{itemize}
  \item The registered \code{@Async} accumulators for an activity are
    the registered \code{@Sync} and \code{@Async} accumulators of its
    parent activity.

  \item The registered \code{@Sync} accumulators for an activity are
    the ones it has created.
  \end{itemize}

This permits computations to be determinate even though accumulators
can be stored in heaps, since no async other the async that created
the accumulator or one of its progeny can actually operate on them.
One can still use the flexibility of the heap to arrange for complex
data-dependent transmission pathways for the accumulator from point of
creation to point of use. e.g.{} arrays of accumulators, hash-maps,
etc. In particular, accumulators can be passed into arbitrary method
invocations, returned from methods etc, with no restrictions.

The method
\begin{lstlisting}
Runtime.isRegistered[T](x:Acc[T]):Int
\end{lstlisting}

\noindent returns \code{0} if \code{x} is not registered with the
current activity, \code{1} if it is \code{@Sync} registered, and \code{2} if
it is \code{@Async} registered.

%%  * Note: Runtime.isRegistered(Clock):Boolean should also be provided
%%    for symmetry.

An invocation \code{e.m(e1,...,en)} of an \code{@Sync} method on an \code{Acc} is
  translated to:
\begin{lstlisting}
{
  val x = e;
  if (Runtime.isRegistered(x) !=1)
    throw new IllegalAccAccess(x);
  Runtime.sync();
  x.m(e1,...,en)
}
\end{lstlisting}
The \code{@Sync} methods on an \code{Acc} are ones that return its
current value (\code{@Read}) and ones that reset it (\code{@Write}).

An invocation \code{e.m(e1,...,en)} of an \code{@Async} method on an
\code{Acc} is translated to:
\begin{lstlisting}
{
  val x = e;
  if (Runtime.isRegistered(x)==0)
    throw new IllegalAccAccess(x);
  x.m(e1,...,en);
}
\end{lstlisting}

The only \code{@Async} method on an \code{Acc} is the one that offers an
update to its value (\code{@Write}).

In many cases the compiler can statically evaluate whether
\code{Runtime.isRegistered(x) > 0} and/or whether a call to
\code{Runtime.sync()}  will suspend.

It may then appropriately simplify the above code. e.g.{}~in the code below
\begin{lstlisting}
val x:Acc[Int] = new Acc[Int](0, Int.+);
finish for (i in 0..100000) async
   x <- i;
Console.OUT.println("x is " + x());
\end{lstlisting}
\noindent the compiler can infer that \code{x()} wont suspend, due to
the \code{finish}. Hence it may eliminate the run-time suspension
check. Further it can establish that \code{x} is \code{@Sync}
registered with the current activity, hence it can eliminate the
access check.

Notes:
\begin{itemize}
\item
   Accs are first-class values. There are no restrictions in storing
   them in data-structures, reading them, passing them as arguments to
   methods, returning them from methods etc.

   However, any attempt to use it will fail unless the Acc is
   registered with the current activity.

\item The runtime checks in \code{Runtime.sync()} and
  \code{Runtime.registered(..)}  ensure that the operations on an \code{Acc}
  are determinate.

\end{itemize}

\begin{proposition}
\code{Acc}'s are determinate under arbitrary usage.
\end{proposition}

\subsection{Example use of \code{Acc}}
\begin{example}[Histogram]
\begin{lstlisting}

\end{lstlisting}
\end{example}

\begin{example}[Distributed word-count]
\begin{lstlisting}
 // A DistHashMap is used because the input is a DistStream

 @det
 def wordCount(m:DistStream[Word]):DistHashMap[Word,Int](m.dist) {
   val a = new DistHashMap[Word, Acc[Int]](m.dist,
          (w:Word)=> new Acc[Int](Int.Sum)));
   finish for (p in m.dist.places()) async at(p) {
      for (word in m(p).words())
          a(word)<- 1;
   }
   return  new DistHashMap[Word, Int](m.dist, (w:Word)=> a(w));
}
\end{lstlisting}

\end{example}


Accumulators can be used to implement collective operations such as
all-to-all reductions in a straightforward ``shared memory'' style.

Here we show the single-sided, blocking version.
\begin{example}
  \begin{lstlisting}
@det
def reduce[T](in:DistArray[T], red:Reducible[T]):T {
  val acc = new Acc[T](red);
  val temp = new GlobalRef[Acc[T]](acc);
  finish for (dest in in.dist.places()) async at(dest) {
    val local = new Acc[T](red);
    for (p in in.dist | here) {
      local <- in(p);
    }
    val x = local();
    async at(origin) temp() <- x;
  }
  return acc();
}
\end{lstlisting}
\end{example}

An \code{allReduce} can be implemented by following the above
operation with a broadcast:
\begin{lstlisting}
  @det
  def allReduce[T](in:DistArray[T]{self.dist==Dist.UNIQUE},
    red:Reducible[T], out:DistArray[T](in.dist)):void {
    val x = reduce(in, red);
    finish for (dest in out.dist.places()) async at (dest) {
      for (p in out.dist |here)
        out(p)=x;
    }
  }
\end{lstlisting}
One can write this code using a clock (to avoid two finish nests).

The collective style requires extending clock so the advance method
takes arbitrary args and performs collective operations on them,
mimicking the MPI API.

\paragraph{Collecting \code{finish}}

The collecting \code{finish} construct is of the form \code{finish(r)
  S}, where \code{r} is an instance of \code{Reducible[T]} and
\code{S} is a statement. Within the dynamic execution of \code{S}, any
execution of the statement \code{offer t;} results in a value \code{t}
being accumulated in a set. (\code{t} must be of type \code{T}.) The
result of the reduction of this set of \code{T} values with \code{r}
is then returned.

\begin{lstlisting}
  {
    val x = new Acc[T](r);
    finish {
      S [ x <- t / offer t;]
    }
    x()
  }
\end{lstlisting}

An attractive aspect of collecting finish is that nesting is used
quite naturally to reflect the relationship between the parallel
computation performing the accumulation and the value returned. In
particular there is no need to explicitly introduce the notion of an
accumulator, or to register it with the current block, or to check
that other activities in the current block have quiesced.

On the other hand, this strength is also a limitation. It is not
possible to use the same idiom for clocked code, i.e.{} collect values
being offered by multiple \code{clocked} asyncs in the current phase.
Further, using this idiom safely across method calls requires the
addition of \code{offers T} clauses (similar to \code{throws T})
clauses, specifying the type of the value being offered. Otherwise at
run-time a value of an incompatible type may be offered leading to a
run-time exception. Finally, the lack of a name for the result being
collecting means that it is difficult to use the same computation to
accumulate multiple separate values without more contortions. e.g.{}
one could set the return type to be a tuple of values, but then the
\code{offer} statement would need to specify the index for which the
\code{offer} was intended. Now it is not clear that the index type
should be arithmetic -- why should not one be able to collect into the
range of a \code{HashMap} (so the index type could be an arbitrary
type \code{Key})?

We feel that these decisions are all orthogonal to the actual process
of accumulating and should be dealt with by the data-structuring
aspects of the language design.

\subsection{Clocked types}

The central idea behind clocked data-structures is that read/write
conflicts are avoided using ``double buffering.'' Two versions of the
data-structure are kept, the {\em current} and the {\em next}
versions. Reads can be performed simultaneously by multiple activities
-- they are performed on the current version of the
data-structure. Writes are performed on the next version of the
data-structure. On detection of termination of the current phase --
when all involved activities are quiescent -- the current and the next
versions are switched.

\code{Clocked[T]} and \code{ClockedAcc[T]} are distinguished in that
unlike the former the latter permits accumulation operations.

Clocked objects are registered with activities, just like
accumulators.  This permits computations to be determinate even though
objects can be stored in heaps, since no async other than a child of
the async that creates the clocked object can actually operate on
them.

Each async (dynamically) has a set of registered clocked values. The
registered clocked values for an activity are the clocked values it
has created, and the ones registered to its parent activity.

\code{Clocked[T]}  has a constructor that takes two \code{T} arguments, these are
used to initialize the now and next fields. These arguments should be
``new'' (that is, no other data-structure should have a reference to
these arguments).

For \code{x:Clocked[T]} the following operations available to any activity on which \code{x}
is registered:
\begin{itemize}
\item \code{x()} -- this returns the value of the current field.

\item \code{x() = t} -- This is translated to x.next()=t. That is, the
  value of the next field is set. Note:
     write-write conflicts are possible since multiple activities may
     try to set the value at the same time.
\item\code{x.finalized()} -- this returns the value of the now field
  but modifies the internal state so that any subsequent attempt to
  use \code{x()=t} will result in a runtime exception.
\end{itemize}

\code{ClockedAcc[T]} has a constructor that takes two \code{T} values and a
\code{Reducer[T]} as argument. The two \code{T} values are used to initialize the
current and next fields. These arguments should be ``new'' (that is, no
other data-structure should have a reference to these arguments). The
reducer is used to perform accumulate operations.

Operations for \code{x:ClockedAcc[T]}:
\begin{itemize}
\item \code{x()} -- this returns the value of the now field.
\item\code{x() <- t} -- this accumulates \code{t} into the next field. Note: No
     write-write conflicts are possible.
\item\code{x() = t} -- this resets the value of the next field to \code{t}. To avoid
     read/write and write/write conflics, this operation should be
     invoked only by the closure argument of
     \code{Clock.advanceAll(closure)}. (See below.)
\item \code{x.finalized()} -- this returns the value of the now field but
     modifies the internal state so that any attempt to use  \code{x()=t}
     or \code{x() <- t} will result in a runtime exception.
\end{itemize}

We add the following method on Clock:
\begin{lstlisting}
public static def advanceAll(x:()=>void) {...}
\end{lstlisting}

If all activities registered on the clock invoke \code{advanceAll(f)}
(for the same value \code{f}), then \code{f} is guaranteed to be
invoked by some activity A registered on the clock at a point in time
when all other activities have entered the \code{advanceAll(f)} call
and the current/next swap has been performed for all registered
clocked values.  At this point -- also called the {\em clock quiescent
point} -- it is guaranteed that none of the other activities are
performing a read or write operation on user-accessible memory.

(A possible implementation of \code{Clocked[T]} and
\code{ClockedAcc[T]} is that a system-synthesized closure (that
performs the current/next swap) is run at the clock quiescent point
before the user specified closure is run.)


\input {examples/stencil.x10}


In the example above there is no need to reinitialize the value of
\code{err()} between phases since the value will monotonically
decrease. However for some other computations this may be
necessary. For example, suppose the error metric was the sum of all
errors. The the above code would change as follows. We would pass in a
different reduction operation red that sums rather than returns a max.
Further, we would replace the \code{Clock.advanceAll()} call with
\begin{lstlisting}
  Clock.advanceAll(()=>{err()=0.0D;});
\end{lstlisting}

This resets the next value of err to be \code{0.0D} before the accumulations
start to happen.
