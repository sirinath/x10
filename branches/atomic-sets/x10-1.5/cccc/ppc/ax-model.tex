\documentclass[10pt]{article}
\usepackage{makeidx}
\usepackage{latexsym}
\usepackage[monochrome]{color}
\usepackage{url}
\usepackage{times}

\newcommand{\derives}{\longrightarrow}
\newcommand{\var}{\mbox{\bf var}}
\def\Hat{{\tt \char`\^}}
\newcommand{\defeq}{\stackrel{def}{=}}
\def\trans#1{\stackrel{#1}{\derives}}
\def\from#1\infer#2{{{\textstyle #1}\over{\textstyle #2}}}
\def\starderives{\stackrel{\star}{\longrightarrow}}
\def\derives{\longrightarrow}
\def\withmmode#1{\relax\ifmmode#1\else{$#1$}\fi}
\def\withmath#1{\relax\ifmmode#1\else{$#1$}\fi}
\def\alt{\withmmode{\;{\tt\char`\|}\;}}
\def\then{\withmath{\;\rightarrow\;}}
\def\tuple#1{\withmath{\langle #1 \rangle}}
\def\dom#1{\mbox{\em dom}(#1)}
\def\clocked{\mbox{\tt clocked}}
\newtheorem{example}{Example}[section]

% \usepackage{macros}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}

\def\llb{\withmath{\lbrack\!\lbrack}}
\def\rrb{\withmath{\rbrack\!\rbrack}}
\def\llbb{\withmath{\lbrack\!{\tt\char`\|}}}
\def\rrbb{\withmath{{\tt\char`\|}\;\rbrack}}

% Changed 7 August to allow use of built-in \ll
\def\LL#1{\withmath{\llb \mbox{\tt #1} \rrb}}
\def\MLL#1{\withmath{\llb #1 \rrb}}
\newcommand{\load}[1]{\mbox{\bf\em load}(#1)}
\newcommand{\store}[1]{\mbox{\bf\em store}(#1)}
\newcommand{\minimal}[1]{\mbox{\em min}(#1)}
\newcommand{\init}{\mbox{\em init}}
\newcommand{\zero}{\mbox{\em zero}}
\def\sync{\mbox{\bf\em sync}}
\def\icbi{\mbox{\bf\em icbi}}
\def\dcbt{\mbox{\bf\em dcbt}}
\def\loads{\mbox{\em loads}}
\begin{document}

\section{Basic terminology}

(For consistency I am using the terminology in Sebastian's note.)

Basic sets:

\begin{tabular}[t]{ll}
 $P$ & set of processors, is $\{1,\ldots, n\}$ for some number $n \in \aleph$\\
 $A$ & set of storage addresses  \\
 $V$ & set of values \\
 $i(a)$ & initial value of location $a\in A$; ranges over $V$\\
\end{tabular}

\noindent Event structure:

\begin{tabular}[t]{ll}
 $E$ & set of events\\
 $t(e) \in \{load,store,sync\}$ & type of event $e\in E$\\
 $p(e)\in P$ & processor that executes event $e \in E$ \\
 $a(e)\in A$ & storage address used by event $e\in E$ \\
 $v(e)\in V$ & value loaded or stored by event $e\in E$\\
\end{tabular}

\noindent Derived notation:

\begin{tabular}[t]{lll}
 $E(p)$ & events executed by processor $p$ &$=\{e\in E\alt p(e)=p\}$\\
 $L,S,F$ & load/store/sync (fence) events & \\
 $L(p),S(p),F(p)$ & stores executed by processor $p$ \\
 $S(a)$ & store events to address $a$ & $=\{s \in S\alt a(s)=a\}$\\
 $L_f$ & local loads ordered by sync $f$ & $=L\cap F(f)$\\
\end{tabular}

\section{The PPC-Core model PPCw }\label{sec:no-remote}
In this model, the requirement ``load must be performed wrt processor
$q$'' does not place any restriction on the behavior of $q$.

\noindent Write order:

\begin{tabular}[t]{ll}
  $<_w$ & is a total order over $S(a)$ for all $a\in A$
\end{tabular}

\noindent Process-local orders:

\begin{tabular}[t]{ll}
$<_p$ & is a partial order over $E$ that is total on $E(p)$, for each
$p\in P$,
\end{tabular}

\noindent We define $V(p)$ the set of {\em events seen by processor
$p$} as $\{e\alt \exists e' \in E: e <_p e' \vee e' <_p e\}$. (Note:
for $E(p)$ containing at least $2$ elements, $E(p) \subseteq V(p)$.)

The tuple $(E,<_w,<_1, \ldots, <_n)$ is a {\em valid execution} if the
following axioms are satisfied.

\paragraph{Coherence.}
For any processor $p$,  
$\forall a\in A;s,s'\in S(a): s <_p s' \Rightarrow s <_w s'$.

\paragraph{Value flow.} Each load gets the value of the latest preceding store 
to the same address that the processor observes, or the initial value
if there is no such store. 
Formally, for all processors $p$ and all loads $l \in L(p)$:

\begin{tabular}[t]{ll}
(V1) & $v(l)=i(a(l))   \vee \exists s\in S(a(l)): s <_p l$ \\
(V2) & $\forall s \in S(a(l))\cap V(p):$\\
& $(\exists s'\in S(a(l)): s <_p s' <_p l) \vee v(l)=v(s)\vee l <_{p} s$
\end{tabular}

{}\paragraph{Fence Accumulation.} 
Fences order stores so that they are globally visible.

For every store $s\in S(a)$, define $\loads(s)$, the set of loads
which read from $s$ by:
$$\loads(s) = \{ l \in L(a(s))\alt s <_{p(l)} l, 
\forall s'\in S(a(l)): s' <_{p(l)} l \Rightarrow s' <_{p(l)} s \vee s'=s\}$$

We can now formalize the barrier requirements (Section~\ref{sec:barrier}).
For any fence $f$, and processor $p=p(f)$ both the following
conditions must hold:

\begin{tabular}[t]{ll}
(F1) & $\forall e\in E,e'\in E(p): e <_p f <_p e' \Rightarrow \forall q\in P: e <_q e'$\\
(F2) & $\forall e\in E,s\in S(p),l\in\loads(s): e <_p f <_p s,  l <_{p(l)} e' \Rightarrow \forall q\in P: e <_q e'$\\
\end{tabular}


\subsection{Examples}

\begin{example}[Dekker: Permitted]
Consider the program:
\begin{verbatim}
p=1         p=2         
[1] x=1     [3] y=1
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

By program order and (F1):
$$ 
\begin{array}{l}
[1] <_1 [1s], [1s] <_1 [2], [3] <_2 [3s], [3s] <_2 [4],\\{}
[3] <_1 [4], [1] <_2 [2]  
\end{array}
$$

Now $[3]\in V(1)$, therefore (V2) forces $[2] <_1 [3]$ (in order for
$[2]$ to return $0$). Therefore $[1] <_1 [3]$. Unfortunately there is
no way to turn this into $[1] <_2 [3]$ (this would be one way of
getting a contradiction). The only way to do so would be by applying
(F1) or (F2). But (F1) is not applicable to the pair $([1],[3])$,
since $[3]$ is not in $E(1)$. (F2) is not applicable because there is
no store in $\{[2]\}$, the $B$-set of the sync for $p=1$.

Therefore we have an execution:

\begin{tabular}[t]{ll}
  $E=$ & $\{[1],\ldots, [4]\}$ \\
  $<_w$ & $\emptyset$\\
  $<_1$ & $[1] <_1 [1s], [1s] <_1 [2], [2] <_1 [3], [3] <_1 [4]$\\{}
  $<_2$ & $[3] <_2 [3s], [3s] <_2 [4], [4] <_2 [1], [1] <_2 [2]$\\{}
\end{tabular}

Note that $[1] <_1 [4]$ does not cause a contradiction because the
relevant condition (V2) applies only to loads $l$ at processors
$p=p(l)$. Effectively, this semantics places no restrictions on
$<_p$ due to foreign loads (loads $l$ s.t. $p(l) \not= p$).

\end{example}

\begin{example}[IRIW: Permitted]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     p=4
[1a] _=x(1) [3] _=y(1)  [1] x=1 [3] y=1
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

The analysis is as above.
\end{example}

\begin{example}[Causal Consistency, CC: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     
[1a] _=x(1) [3] _=y(1)  [1] x=1 
[1s]sync    [3s] sync
[2] y=1     [4] _=x(0)
\end{verbatim}

This is not an execution of PPCw. 

(V2) forces $[1]$ to be visible at $p=1$, and $[1] <_1 [1a]$, and
hence $[1] <_1 [2]$. (F1) causes $[1] <_2 [2]$.  (V2) forces $[2] <_2
[3]$. Therefore it follows that $[1] <_2 [4]$ and hence $[4]$ must
return $1$.
  
\end{example}

\begin{example}[Longer Causal Consistency, CC: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3      p=4
[1a] _=x(1) [3] _=y(1)  [1] x=1  [5] _=z(1)
[1s]sync    [3s] sync            [5s] sync
[2] y=1     [4] z=1              [6] _=x(0)
\end{verbatim}

This is not an execution of PPCw. The same reasoning as in the
previous example, carried through one more step.

(V2) forces $[1]$ to be visible at $p=1$, and $[1] <_1 [1a]$, and
hence $[1] <_1 [2]$. (F1) causes $[1] <_2 [2]$.  (V2) forces $[2] <_2
[3]$. Therefore it follows that $[1] <_2 [3s] <_2 [4]$. Now (F1)
can be applied to transfer $[1] <_2 [4]$ to $<_4$. This forces
$[6]$ to read $1$.
  
\end{example}

\begin{example}[Direct Consistency, DC: Permitted]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     
[1a] _=x(1) [3] y=1     [1] x=1 
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

This is a variant of Dekker that is permitted because Dekker is:

\begin{tabular}[t]{ll}
  $E=$ & $\{[1],\ldots, [4]\}$ \\
  $<_w$ & $\emptyset$\\
  $<_1$ & $[1] <_1 [1a] <_1 [1s] <_1 [2] <_1 [3] <_1 [4]$\\{}
  $<_2$ & $[3] <_2 [3s] <_2 [4] <_2 [1] <_2 [1a] <_2 [2]$\\{}
\end{tabular}

\end{example}

\begin{example}[LF -- Lock-free Stack/Queue/List:Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         
[1] x=1     [3] _=y(1)
[1s] sync   [3s] sync
[2] y=1     [4] r2=x(0)
\end{verbatim}

This example is a direct application of (F2) to $[1],[2],[3]$ and
$[4]$ yielding $[1] <_2 [4]$, hence $[4]$ must return $1$.
  
\end{example}
\begin{example}[Snapshot: Permitted]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     p=4
[1a] _=x(1) [3] _=x(0)  [1] x=1 [3] y=1
[1s] sync   [3s] sync
[2] _=y(0)  [4] _=y(1)
[2s] sync   [4s] sync
[2b] _=x(1) [4b] _=x(0)
\end{verbatim}

This is permitted. We will get $[1] <_1 [1a]$, and hence by (F1) $[1]
<_2 [2]$, and by (V2), $[4b] <_2 [1]$. However, the $[4] <_2 [2]$ does
not generate a contradiction because $[2]$ is a foreign load.

\end{example}


\section{The PPC-Core model PPCs}\label{sec:remote-is-local}

In this model, the requirement ``load $l$ must be performed wrt
processor $q$'' is interpreted as ``load $l$ must return the same
value when it is performed wrt processor $q$.''

This is formalized by requiring that (V1) and (V2) apply to all loads
$l \in V(p)$ (and not just loads $l\in L(p)$).

\begin{example}[Dekker: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         
[1] x=1     [3] y=1
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

By program order and (F1):
$$ 
\begin{array}{l}
[1] <_1 [1s], [1s] <_1 [2], [3] <_2 [3s], [3s] <_2 [4],\\{}
[3] <_1 [4], [1] <_2 [2]  
\end{array}
$$

Now $[3]\in V(1)$, therefore (V2) forces $[2] <_1 [3]$ (in order for
$[2]$ to return $0$). Therefore $[1] <_1 [3]$, and hence 
$[1] <_1 [4]$. But then the value returned by $[4]$ should be $1$, not $0$. 

So this is not an execution. 
\end{example}

\begin{example}[IRIW: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     p=4
[1a] _=x(1) [3] _=y(1)  [1] x=1 [3] y=1
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

The analysis is as above.
\end{example}

CC, LCC, LF are forbidden by PPCw, and hence by PPCs. 

\begin{example}[Direct Consistency, DC: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     
[1a] _=x(1) [3] y=1     [1] x=1 
[1s]sync    [3s] sync
[2] _=y(0)  [4] _=x(0)
\end{verbatim}

This is forbidden  because Dekker is. The execution permitted by PPCw:

\begin{tabular}[t]{ll}
  $E=$ & $\{[1],\ldots, [4]\}$ \\
  $<_w$ & $\emptyset$\\
  $<_1$ & $[1] <_1 [1a] <_1 [1s] <_1 [2] <_1 [3] <_1 [4]$\\{}
  $<_2$ & $[3] <_2 [3s] <_2 [4] <_2 [1] <_2 [1a] <_2 [2]$\\{}
\end{tabular}

is not an execution because $[4]$ must return $1$ in $p=1$.
\end{example}

\begin{example}[Snapshot: Forbidden]
Consider the program:
\begin{verbatim}
p=1         p=2         p=3     p=4
[1a] _=x(1) [3] _=x(0)  [1] x=1 [3] y=1
[1s] sync   [3s] sync
[2] _=y(0)  [4] _=y(1)
[2s] sync   [4s] sync
[2b] _=x(1) [4b] _=x(0)
\end{verbatim}

This is forbidden. We will get $[1] <_1 [1a]$, and hence by (F1) $[1]
<_2 [2]$, and by (V2), $[4b] <_2 [1]$. Now $[4] <_2 [2]$ will 
force $[2]$ to read $1$, and this is a contradiction.
\end{example}

{\footnotesize \bibliographystyle{alpha} \bibliography{master,ref} }

\appendix
\section{Rationale and notes}

We model the execution of PowerPC processors executing sequences of
Load, Store and {\em\bf hwsync} (fence, $L=0$ \sync) instructions
against memory that is Memory Coherence Required and is neither Write
Through Required nor Caching Inhibited.


Why introduce $<_w$? We wish to model:
\begin{quotation}
  Atomic stores to a given location are {\em coherent} if they
  are serialized in some order, and no processor or mechanism is able to
  observe any subset of those stores as occurring in a conflicting
  order. This serialization order is an abstract sequence of values; the
  physical storage location need not assume each of the values written to
  it. 
\end{quotation}
Thus $<_w$ captures the total order on all writes to a location, even
if some of the writes are not seen by any processor (other than the
one that performed it).  We do not require that $<_w$ is contained in
$<_p$ to model the idea that not all writes are performed at every
processor. Similarly, $V(p)$ is not required to be $E$, since some
events may never be performed with respect to $p$ (e.g.{} because the
processor that performed them did not use fences).

The requirement:
\begin{quotation}
The sequence of values loaded from the location by any processor
during an interval of time forms a subsequence of the sequence of
values that the location logically held during that interval.
\end{quotation}
is captured by the formal Coherence condition.

Why model $<_p$ as a partial order rather than a total order?  We have
sought to model a load being performed against another processor, not
just a store. Hence $V(p)$ may include loads belonging to other
processors. However, there is no language in the redbooks which
requires these loads to be totally ordered at $p$.

We turn to the fence conditions. (F1) captures the dependency between
the cumulative $A$ set and those elements in $B$ belonging to the
process $p$. (F2) directly captures the cumulativity clause for $B$.

\section{Text from the PowerPC redbooks}

\subsection{Performed}\label{sec:performed}
From \cite[p.~10]{ppc-2}, the definition of {\em performed}
\begin{quotation}
{\em 
A load or instruction fetch by a processor or mechanism (P1) is
performed with respect to any processor or mechanism (P2) when the
value to be returned by the load or instruction fetch can no longer be
changed by a store by P2. A store by P1 is performed with respect to
P2 when a load by P2 from the location accessed by the store will
return the value stored (or a value stored subsequently). 
}  
\end{quotation}
\subsection{Memory Coherence Required}\label{sec:memory-coherence}
From \cite[p.~5,Sec~1.6.3]{ppc-2}: 
\begin{quotation}
An access to a Memory Coherence Required storage location is performed coherently, as follows.

Memory coherence refers to the ordering of stores to a single
location. Atomic stores to a given location are {\em coherent} if they
are serialized in some order, and no processor or mechanism is able to
observe any subset of those stores as occurring in a conflicting
order. This serialization order is an abstract sequence of values; the
physical storage location need not assume each of the values written to
it. For example, a processor may update a location several times
before the value is written to physical storage. The result of a store
operation is not available to every processor or mechanism at the same
instant, and it may be that a processor or mechanism observes only
some of the values that are written to a location. However, when a
location is accessed atomically and coherently by all processor and
mechanisms, the sequence of values loaded from the location by any
processor or mechanism during any interval of time forms a subsequence
of the sequence of values that the location logically held during that
interval. That is, a processor or mechanism can never load a ``newer''
value first, and then, later, load an ``older'' value.
\end{quotation}
\subsection{Barrier}\label{sec:barrier}
From \cite[p.~15,Sec~1.7.1]{ppc-2}: 

\begin{quotation}
When a processor (P1) executes a {\em Synchronize} or {\em eieio} instruction a
{\em memory barrier} is created, which orders applicable storage
accesses pairwise, as follows. Let $A$ be a set of storage accesses that
includes all storage accesses associated with instructions preceding
the barrier-creating instruction, and let $B$ be a set of storage
accesses that includes all storage accesses associated with
instructions following the barrier-creating instruction. For each
applicable pair $a_i$, $b_j$ of storage accesses such that $a_i$ is in $A$ and 
$b_j$ is in $B$, the memory barrier ensures that $a_i$ will be performed with
respect to any processor or mechanism, to the extent required by the
associated Memory Coherence Required attributes, before $b_j$ is
performed with respect to that processor mechanism.

The ordering done by a memory barrier is said to be ``cumulative'' if
it also orders storage accesses that are performed by processors and
mechanisms other than P1, as follows:
\begin{itemize}
  \item $A$ includes all applicable storage acccesses by any such
  processor or mechanism that have been performed with respect to P1
  before the memory barrier is created.

  \item $B$ includes all applicable storage accesses by any such
  processor or mechanism that are performed after a Load instruction
  executed by that processor or mechanism has returned the value
  stored by a store that is in B.
\end{itemize}

\end{quotation}

\subsection{Sync}\label{sec:sync}
From \cite[p.~26,Sec 3.3.3]{ppc-2}: 
\begin{quotation}
  The {\sync} instruction creates a memory barrier (see Section
  1.7.1). The set of storage accesses that is ordered by the memory
  barrier depends on the value of the L field.

  \begin{description}
    \item[L=0(``heavyweight sync'')] 

      The memory barrier provides an ordering function for the storage
      accesses associated with all instructions that are executed by
      the processor executing the {\sync} instruction. The
      applicable pairs are all pairs $a_i,b_j$ in which $b_j$ is a
      data access, except that if $a_i$ is the storage access caused
      by an {\em\bf icbi} instruction then $b_j$ may be performed with
      respect to the processor executing the {\sync}
      instruction before $a_i$ is performed with respect to that
      processor.
    \item[L=1 (``lightweight sync'')]

      The memory barrier provides an ordering function for the storage
      accesses caused by {\em Load}, {\em Store}, and {\em\bf dcbz}
      instructions that are executed by the processor executing
      the{\bf sync} instruction and for which the specified storage
      location is in storage that is Memory Coherence Required and is
      neither Write Through Required nor Caching Inhibited. The
      applicable pairs are all pairs $a_i,b_j$ of such accesses except
      those in which $a_i$ is an access caused by a Store or {\em\bf
      dcbz} instruction and $b_j$ is an access caused by a {\em Load}
      instruction.

  \end{description}

The ordering done by the memory barriers is cumulative.

If L=0 (or L=2), the {\sync} instruction has the following
additional properties:

\begin{itemize}
  \item Executing the {\sync} instruction ensures that all
  instructions preceding the {\sync} instruction have completed
  before the {\sync} instruction completes, and that no
  subsequent instructions are initiated until after the {\sync}
  instruction completes.

  \item The {\sync} instruction is execution synchronizing (see
   Book III, {\em PowerPC Operating Environment
   Architecture}). However, address translation and reference and
   change recording (see Book III) associated with subsequent
   instructions may be performed before the {\sync} instruction
   completes.

 \item The memory barrier provides the additional ordering function
   such that if a given instruction that is the result of a {\em Store}
   in set B is executed, all applicable storage accesses in set A have
   been perforemd with respect to the processor executing the instruction
   to the extend required by the associated memory coherence
   properties. The single exception is that any storage access in set A
   that is caused by an {\icbi} instruction executed by the processor
   executing the {\sync} instruction (P1) may not have been performed
   with respect to P1 (see the description of the {\icbi} instruction on
   page 18).

   The cumulative properties of the barrier apply to the execution of the
   given instruction as they would to a Load that returned a value that
   was the result of a {\em Store} in set B.

 \item The {\sync} instruction provides an ordering function for
   the operation caused by {\em\bf dcbr} instruction with $TH_0=1$.
\end{itemize}

The value L=3 is reserved.

The \sync{} instruction may complete before storage accesses
associated with instructions preceding the \sync{} instruction have
been performed. The \sync{} instruction may complete before operations
caused by \dcbt{} instructions with $TH_0 = 1$ preceding the \sync{}
instruction have been performed.  
\end{quotation}


\end{document}