

                    X10Lib : The X10 Runtime System

                              Version 0.5


                        T E S T  H A R N E S S
                        ----------------------

                  (c) Copyright IBM Corporation 2007



This is a brief working notes regarding the submission of test code
into the Automatic Testing Framework that is part of the X10 Runtime
System.

This document is meant for developer's contributing code into the
X10 Runtime System.


!!!WARNING!!! May be revised as the development progresses.


Test Directory Organization
----------------------------

The "test" directory organization is analogous to that of the "src"
directory and the developers are expected to contribute the code in
those subdirs that are relevant to them.

The "test" subdir hier is as follows:

x10.lib ----- test ----- array ------ data
                |
                |------- sched ------ data
                |
                |_______ data


[Note: "pass" and "fail" subdirs are dead CVS subdirs.
	   Please don't include any code those locations.]


* All X10Lib's messaging layer tests should go into the
  main "test" dir itself.

* The X10Lib's array tests should be part of "array"
  subdir.

* The X10Lib's scheduler tests should be part of "sched"
  subdir.

Each subdir also includes a "data" dir for specifying
the test environment and expected results on a case by case
basis.


Guidelines for Test Code Submission
-----------------------------------

A developer has to do following things in order for his test
to become part of the test harness:

01) The source for each test case should be in a single or
    multiple files with appropriate language suffixes
    (.c/.cc/.cxx/.cpp/.C).


Modification required to the Makefile
-------------------------------------

02) Once the test case is prepared add the following lines
    to the Makefile in the respective subdir:

      + TARGETn = test_case_name

      + SRCSn   = src_file1 src_file2 ... src_filen
    [Each source file should have one of the above mentioned
     suffixes.]

      + OBJSn = obj_file1 obj_file2 ... obj_filen
    [Each object file corresponds to the previously listed source
     files on one to one basis with source suffix replaced by '.o'.]

03) Add your target to the existing list of targets.

      + TARGETS = ... $(TARGETn)

04) Add the following lines to the Makefile for building your
    test case:

      + $(TARGETn): $(OBJSn)

      + [tab]$(RM) $@

      + [tab]$(CXX) $(LINKFLAGS) $(OBJSn) -o $@ $(LIBDIRS) $(LIBS)

        (or)

      + [tab]$(CC) $(LINKFLAGS) $(OBJSn) -o $@ $(LIBDIRS) $(LIBS)

05) If your source files require special compilation or additional
    flags, you may have to add the following lines as well:

      + obj_filen: src_filen

      + [tab]$(RM) $@

      + [tab]$(CXX) $(CXXFLAGS) $(DEFS) custom_flags (or)
					command_vars $(INCLUDES) $< -o $@

        (or)

      + [tab]$(CC) $(CXXFLAGS) $(DEFS) custom_flags (or)
	                command_vars $(INCLUDES) $< -o $@

06) Also update the "clean" section in the same Makefile.

    clean:

      [tab]...

      + [tab]$(RM) ... $(OBJSn)


Modifications required to the test harness script (xxxxx_test.sh)
-----------------------------------------------------------------

07) Lookout for the test harness script in the same subdir and
    add your test case to the list of existing test cases:

    + for i in ... test_case_name
      do
      .....
      done


Additions required to the respective "data" subdir
--------------------------------------------------

08) You should create two files in the "data" subdir in order
    to execute your test case automatically:

    a) test_case_name.cmd
	   ------------------
       [Test Case Command Script]

       While preparing this script follow sh/ksh scripting
       conventions.

       Basically you require one line similar to the following:

       For sequential execution:
	   -------------------------

           $1

       For parallel execution:
       -----------------------

           poe $1 -procs n


       * Keep $1 as it is; Don't substitue any thing there.
         While executing your test case, it will be automatically
         replaced by the appropriate command line.

       * Replace n with number of parallel tasks you require for
         execution.

       * Optionally, export any variables you require for properly
         executing the test case using 'export' keyword.

       * Also, add any other command flags or variables you required
         for proper execution.

    b) test_case_name.dat
       ------------------
       [Test Case Expected Results]

       Provide a data file whose contents are the expected results
       from executing the said test case.

       You can prepare this data file by building and executing
       the test case outside the testing framework and redirecting
       the results.

       During automatic testing phase the expected results will be
       compared with the actual outcome and the test execution will
       be marked as "OK" or "Failed".


Implementation Details
----------------------

The main regression test script (regress.sh) automatically invokes
the local test scripts (core_test.sh, array_test.sh, and sched_test.sh)
for sequencing and executing the enlisted test cases one after
another and reports any failures to the autorun process.
